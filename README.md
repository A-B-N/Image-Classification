# Image-Classification
1. Initial Processes: All the libraries necessary for the problem has been imported in the first step. The train images were loaded using glob API, which is used for loading all the files ending with, “.jpg”. In the same way, Test images were also loaded using the glob API. The train labels were imported using read_csv function available in Pandas.

2. Feature Extraction and Scaling: After extracting the train images, the features present in the train images were extracted using color histogram technique. Only the histograms were extracted from the images, while bins and edges were excluded. Then a describe function was used, which was used to extract the histogram for each image, flattened it and appended it as a nd array. The images in train and test were passed separately into the describe function, there by obtaining arrays of features extracted from their respective images. The arrays obtained were then scaled using standard scaler function available in Scikit-learn preprocessing module. It fits and scales both the train and test features separately.

3. Dimentionality Reduction : Although not used in the main program, Truncated Single Value Decomposition(Truncated SVD) technique was performed on both the train and the test arrays and those values were used by Support Vector Machine(SVM) classifier to predict and the F1- score was computed. Since a F1- score of just 0.5783 was obtained, this was not considered for the final analysis.

4. Selection of Classifier: Three different classifiers were selected for the analysis namely, K-nearest neighbors classifier, Support Vector Machine classifier and Extra trees Classifier which was performed on the traffic-small dataset using the scaled features. Since the dataset was imbalanced, F1-score was used as the performance metric. First the analysis was performed on Support Vector Machine Classifier. For the kernel type, “Gaussian Radial Basis Function”, F1- score of just 0.57. Then a different kernel namely, “polynomial” kernel was chosen , for which , F1- score of 0.6633 was obtained.
      After SVM,K- Nearest Neighbors classifier was chosen for the analysis. For k=7, F1- score of 0.62 was obtained. Then for k=22, F1-score of 0.6408 was obtained. Since the F1-score of KNN
classifier with k=21 was less than the F1-Score of SVM classifier with “polynomial” kernel, it was immediately discarded from further considerations as a choice of classifier.
      After, K-NN classifier, Extra Trees Classifier was chosen for the analysis. For n_estimators = 50, F1-score of 0.6742 was obtained. For n_estimators = 100, F1-score of 0.6933 was obtained. For n_estimators = 150, F1-score obtained was reduced back to 0.67. Hence an intermediate value for n_estimator = 120 was chosen, which gave a F1-score of 0.7003.
Since the F1-score of Extra trees classifier with n_estimators=120 was greater than SVM with polynomial kernel, Extra Trees Classifier was chosen for the final analysis with traffic dataset.

5. Execution: The final classifier model was Extra trees classifier with n_estimators =120, max_features=20 and random_state=7. This model was trained on the scaled train data in the traffic dataset along with its labels and was used to predict on the scaled test dataset . F1-score of 0.8857 was obtained. Since the optimal n_estimators were determined earlier, max_features were varied to find the variations in the F1-score. For max_features =25, F1-score of 0.8879 was obtained. Since the F1-score improved with increase in features, it was incremented again to 27 for which F1-score of 0.8895 was obtained. For max_features = 32, however, the F1-score dropped back to 0.8873. Hence, a value of 27 was considered optimal for max_features and the final F1-score of 0.8895 was submitted
